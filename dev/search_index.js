var documenterSearchIndex = {"docs":
[{"location":"benchs/#Benchmark-Report-for-*HMatrices*","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"","category":"section"},{"location":"benchs/#Job-Properties","page":"Benchmark Report for HMatrices","title":"Job Properties","text":"","category":"section"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"Time of benchmark: 2 May 2021 - 10:7\nPackage commit: dirty\nJulia commit: 6aaede\nJulia command flags: -O3\nEnvironment variables: JULIA_NUM_THREADS => 1 OPEN_BLAS_NUM_THREADS => 1","category":"page"},{"location":"benchs/#Results","page":"Benchmark Report for HMatrices","title":"Results","text":"","category":"section"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"Below is a table of this job's results, obtained by running the benchmarks. The values listed in the ID column have the structure [parent_group, child_group, ..., key], and can be used to index into the BaseBenchmarks suite to retrieve the corresponding benchmarks. The percentages accompanying time and memory values in the below table are noise tolerances. The \"true\" time/memory value for a given benchmark is expected to fall within this percentage of the reported value. An empty cell means that the value was zero.","category":"page"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"ID time GC time memory allocations\n[\"Assembly\", \"Laplace kernel 50000\"] 1.476 s (5%) 192.301 ms 1.46 GiB (1%) 245868\n[\"Compressors\", \"ACA(0.0, 9223372036854775807, 1.0e-6)\"] 173.728 ms (5%) 11.996 ms 206.40 MiB (1%) 92\n[\"Compressors\", \"PartialACA(0.0, 9223372036854775807, 1.0e-6)\"] 283.944 μs (5%)  419.19 KiB (1%) 44\n[\"Compressors\", \"TSVD(0.0, 9223372036854775807, 1.0e-6)\"] 141.331 ms (5%) 854.505 μs 46.04 MiB (1%) 15","category":"page"},{"location":"benchs/#Benchmark-Group-List","page":"Benchmark Report for HMatrices","title":"Benchmark Group List","text":"","category":"section"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"Here's a list of all the benchmark groups executed by this job:","category":"page"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"[\"Assembly\"]\n[\"Compressors\"]","category":"page"},{"location":"benchs/#Julia-versioninfo","page":"Benchmark Report for HMatrices","title":"Julia versioninfo","text":"","category":"section"},{"location":"benchs/","page":"Benchmark Report for HMatrices","title":"Benchmark Report for HMatrices","text":"Julia Version 1.6.1\nCommit 6aaedecc44 (2021-04-23 05:59 UTC)\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin18.7.0)\n  uname: Darwin 20.3.0 Darwin Kernel Version 20.3.0: Thu Jan 21 00:07:06 PST 2021; root:xnu-7195.81.3~1/RELEASE_X86_64 x86_64 i386\n  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz: \n                 speed         user         nice          sys         idle          irq\n       #1-16  2300 MHz    1073909 s          0 s     570700 s   25879754 s          0 s\n       \n  Memory: 16.0 GB (2096.8046875 MB free)\n  Uptime: 405641.0 sec\n  Load Avg:  2.9375  2.85498046875  2.7421875\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)","category":"page"},{"location":"hmatrix/#HMatrix-structure","page":"HMatrix structure","title":"HMatrix structure","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"CurrentModule = HMatrices","category":"page"},{"location":"#HMatrices.jl","page":"Getting started","title":"HMatrices.jl","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"A package for assembling and factoring hierarchical matrices with a focus on boundary integral equations","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"This package provides various methods for assembling as well as for doing linear algebra with hierarchical matrices. The main structure exported is the HMatrix type, which can be used to efficiently approximate certain linear operators containing a hierarchical low-rank structure. Once assembled, a hierarchical matrix can be used to accelerate the solution of Ax=b in a variety of ways, as illustrated in the examples that follow.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"note: Note\nAlthough hierarchical matrices have a broad range of application, this package focuses on their use to approximate integral operators arising in boundary integral equation methods. ","category":"page"},{"location":"#Assembling-an-HMatrix","page":"Getting started","title":"Assembling an HMatrix","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"In order to assemble an HMatrix, you need the following (problem-specific) ingredients:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The matrix-like object K that you wish to compress\nA hierarchical partition of the rows and columns indices of K\nAn admissibility condition for determining (a priory) whether a block is compressible, and\nA function/functor to generate a low-rank approximation of compressible blocks","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"To illustrate how this is done for a concrete problem, consider two set of points X = left boldsymbolx_i right_i=1^m and Y = left boldsymbolx_j right_j=1^m in mathbbR^3, and let A be an m times n matrix with entries given by:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"  A_ij = exp(-boldsymbolx_i-boldsymboly_j)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The following code will create the point clouds X and Y, as well as the matrix-like object K:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using HMatrices, LinearAlgebra, StaticArrays\nconst Point3D = SVector{3,Float64}\n\nstruct ExponentialMatrix <: AbstractMatrix{Float64}\n  X::Vector{Point3D}  \n  Y::Vector{Point3D}\nend\n\nBase.getindex(K::ExponentialMatrix,i::Int,j::Int) = exp(-norm(K.X[i] - K.Y[j]))\nBase.size(K::ExponentialMatrix) = length(K.X), length(K.Y)\n\n# points on a sphere\nm = n = 10000\nX = Y = [Point3D(sin(θ)cos(ϕ),sin(θ)*sin(ϕ),cos(θ)) for (θ,ϕ) in zip(π*rand(n),2π*rand(n))]\n# create the abstract matrix\nK = ExponentialMatrix(X,Y)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The next step in to partition the point clouds X and Y into a tree-like data structure so that blocks corresponding to well-separated points can be easily distinguished and compressed. The WavePropBase package provides the ClusterTree struct for this purpose:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Xclt = Yclt = ClusterTree(X)\nnothing # hide","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The third requirement is an admissibilty condition to determine if the interaction between two clusters should be compressed. We will use the StrongAdmissibilityStd:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"adm = StrongAdmissibilityStd()\nnothing # hide","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The final step is to provide a method to compress admissible blocks. Here we will use the PartialACA functor:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"comp = PartialACA(;atol=1e-6)\nnothing # hide","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"We can now compress the operator K using","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"H = HMatrix(K,Xclt,Yclt,adm,comp;threads=false,distributed=false)","category":"page"},{"location":"#Matrix-vector-product-and-iterative-solvers","page":"Getting started","title":"Matrix vector product and iterative solvers","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"You can now use H as an approximation to K:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"x = rand(n)\nH*x ≈ K*x ","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The larger the number of points n, the more we expect to gain from this compression technique.","category":"page"},{"location":"#Factorization-and-direct-solvers","page":"Getting started","title":"Factorization and direct solvers","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Although the forward map illustrated in the example above suffices to solve the linear system Kx = b, there are circumnstances when a direct solver is more appropriate (because, e.g., the system is not well-conditioned or you wish to solve it for many right-hand-sides b). At present, you can do an lu factorization of H as follows:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"F = lu(H,comp)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The factorization F can then be used to solve a linear system:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"b = rand(m)\napprox = F\\b\nexact  = Matrix(K)\\b\nnorm(approx-exact,Inf)","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"note: Note\nMost algebraic manipulations of hierarchical matrices require the use of compressor to keep the rank of the low blocks under control when e.g. adding two low-rank blocks. In HMatrices.jl, there are a few options defined in src/compressor.jl.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Note that the error in solving the linear system may be significantly larger than the error in computing H*x due to the condition of the underlying operator.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"tip: Tip\nBecause factoring an HMatrix with a small error tolerance can be quite time-consuming, a hybrid strategy consists of using a rough factorization (with a large tolerance) as a preconditioner to an iterative solver.","category":"page"},{"location":"#Tensor-valued-matrices","page":"Getting started","title":"Tensor-valued matrices","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Some support is currently provided for matrices with entries which are themselves matrices...","category":"page"},{"location":"#References","page":"Getting started","title":"References","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"[1] Hackbusch, Wolfgang. Hierarchical matrices: algorithms and analysis. Vol. 49. Heidelberg: Springer, 2015.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"[2] Bebendorf, Mario. Hierarchical matrices. Springer Berlin Heidelberg, 2008.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Modules = [HMatrices]","category":"page"},{"location":"#Base.Matrix-Tuple{HMatrix}","page":"Getting started","title":"Base.Matrix","text":"Matrix(H::HMatrix;global_index=false)\n\nConvert H to a Matrix. If global_index=true, the entries are given in the global indexing system (see HMatrix for more information); otherwise the local indexing system induced by the row and columns trees are used (default).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.ACA","page":"Getting started","title":"HMatrices.ACA","text":"struct ACA\n\nAdaptive cross approximation algorithm with full pivoting. This structure can be used to generate an RkMatrix from a matrix-like object M as follows:\n\nusing LinearAlgebra\nrtol = 1e-6\ncomp = ACA(;rtol)\nA = rand(10,2)\nB = rand(10,2)\nM = A*adjoint(B) # a low-rank matrix\nR = comp(M,:,:) # compress the entire matrix `M`\nnorm(Matrix(R) - M) < rtol*norm(M) # true\n\n# output\n\ntrue\n\n\nThe keywork arguments rtol, atol, and rank can be used to control the quality of the approximation. Because it uses full pivoting, the linear operator has to be evaluated at every i,j. See also: [PartialACA](@ref).\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.AbstractCompressor","page":"Getting started","title":"HMatrices.AbstractCompressor","text":"abstract type AbstractCompressor\n\nTypes used to compress matrices.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.HMatrix","page":"Getting started","title":"HMatrices.HMatrix","text":"mutable struct HMatrix{R,T} <: AbstractHMatrix{T}\n\nA hierarchial matrix constructed from a rowtree and coltree of type R and holding elements of type T.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.HMatrix-2","page":"Getting started","title":"HMatrices.HMatrix","text":"HMatrix(K,rowtree,coltree,adm,comp;threads=true,distributed=false,permute_kernel=true)\n\nMain constructor for hierarchical matrix, where K represents the matrix to be approximated, rowtree and coltree are tree structure partitioning the row and column indices, respectively, adm can be called on a node of rowtree and a node of coltree to determine if the block is compressible, and comp is a function/functor which can compress admissible blocks.\n\nIt is assumed that K supports getindex(K,i,j), and that comp can be called as comp(K,irange::UnitRange,jrange::UnitRange) to produce a compressed version of K[irange,jrange].\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.HMatrix-Union{Tuple{T}, Tuple{R}, Tuple{R, R, Any}} where {R, T}","page":"Getting started","title":"HMatrices.HMatrix","text":"HMatrix{T}(rowtree,coltree,adm)\n\nConstruct an empty HMatrix with rowtree and coltree using the admissibility condition adm.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.HMulNode","page":"Getting started","title":"HMatrices.HMulNode","text":"struct HMulNode{S,T} <: AbstractTree\n\nTree data structure representing the following computation:\n\n    C <-- C + a * ∑ᵢ Aᵢ * Bᵢ\n\nwhere C = target(node), and Aᵢ,Bᵢ are pairs stored in sources(node).\n\nThis structure is used to group the operations required when multiplying hierarchical matrices so that they can later be executed in a way that minimizes recompression of intermediate computations.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.PartialACA","page":"Getting started","title":"HMatrices.PartialACA","text":"struct PartialACA\n\nAdaptive cross approximation algorithm with partial pivoting. This structure can be used to generate an RkMatrix from a matrix-like object M as follows:\n\nusing LinearAlgebra\nrtol = 1e-6\ncomp = PartialACA(;rtol)\nA = rand(10,2)\nB = rand(10,2)\nM = A*adjoint(B) # a low-rank matrix\nR = comp(M) # compress the entire matrix `M`\nnorm(Matrix(R) - M) < rtol*norm(M) # true\n\n# output\n\ntrue\n\n\nBecause it uses partial pivoting, the linear operator does not have to be evaluated at every i,j. This is usually much faster than ACA, but due to the pivoting strategy the algorithm may fail in special cases, even when the underlying linear operator is of low rank.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.PermutedMatrix","page":"Getting started","title":"HMatrices.PermutedMatrix","text":"PermutedMatrix{K,T} <: AbstractMatrix{T}\n\nStructured used to reprensent the permutation of a matrix-like object. The original matrix is stored in the data::K field, and the permutations are stored in rowperm and colperm.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.RkMatrix","page":"Getting started","title":"HMatrices.RkMatrix","text":"mutable struct RkMatrix{T}\n\nRepresentation of a rank r matrix M in outer product format M = A*adjoint(B) where A has size m × r and B has size n × r.\n\nThe internal representation stores A and B, but R.Bt or R.At can be used to get the respective adjoints.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.RkMatrix-Tuple{LinearAlgebra.SVD}","page":"Getting started","title":"HMatrices.RkMatrix","text":"RkMatrix(F::LinearAlgebra.SVD)\n\nConstruct an RkMatrix from an SVD factorization.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.RkMatrix-Tuple{Matrix{T} where T}","page":"Getting started","title":"HMatrices.RkMatrix","text":"RkMatrix(M::Matrix)\n\nConstruct an RkMatrix from a Matrix by passing through the full svd of M.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.RkMatrix-Union{Tuple{V}, Tuple{Vector{V}, Vector{V}}} where V<:(AbstractVector{T} where T)","page":"Getting started","title":"HMatrices.RkMatrix","text":"RkMatrix(A::Vector{<:Vector},B::Vector{<:Vector})\n\nConstruct an RkMatrix from a vector of vectors. Assumes that length(A) == length(B), which determines the rank, and that all vectors in A (resp. B) have the same length m (resp. n).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.StrongAdmissibilityStd","page":"Getting started","title":"HMatrices.StrongAdmissibilityStd","text":"struct StrongAdmissibilityStd\n\nTwo blocks are admissible under this condition if the minimum of their diameter is smaller than eta times the distance between them, where eta::Float64 is a parameter.\n\nUsage:\n\nadm = StrongAdmissibilityStd(;eta=2.0)\nadm(Xnode,Ynode)\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.TSVD","page":"Getting started","title":"HMatrices.TSVD","text":"struct TSVD\n\nCompression algorithm based on a posteriori truncation of an SVD. This is the optimal approximation in Frobenius norm; however, it also tends to be very expensive and thus should be used mostly for \"small\" matrices.\n\n\n\n\n\n","category":"type"},{"location":"#HMatrices.WeakAdmissibilityStd","page":"Getting started","title":"HMatrices.WeakAdmissibilityStd","text":"struct WeakAdmissibilityStd\n\nTwo blocks are admissible under this condition if the distance between them is positive.\n\n\n\n\n\n","category":"type"},{"location":"#Base.hcat-Union{Tuple{T}, Tuple{HMatrices.RkMatrix{T}, HMatrices.RkMatrix{T}}} where T","page":"Getting started","title":"Base.hcat","text":"hcat(M1::RkMatrix,M2::RkMatrix)\n\nConcatenated M1 and M2 horizontally to produce a new RkMatrix of rank rank(M1)+rank(M2).\n\n\n\n\n\n","category":"method"},{"location":"#Base.vcat-Union{Tuple{T}, Tuple{HMatrices.RkMatrix{T}, HMatrices.RkMatrix{T}}} where T","page":"Getting started","title":"Base.vcat","text":"vcat(M1::RkMatrix,M2::RkMatrix)\n\nConcatenated M1 and M2 vertically to produce a new RkMatrix of rank rank(M1)+rank(M2)\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._aca_full!-NTuple{4, Any}","page":"Getting started","title":"HMatrices._aca_full!","text":"_aca_full!(M,atol,rmax,rtol)\n\nInternal function implementing the adaptive cross-approximation algorithm with full pivoting. The matrix M is modified in place. The returned RkMatrix has rank at most rmax, and is expected to satisfy |M - R| < max(atol,rtol*|M|).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._aca_full_pivot-Tuple{Any}","page":"Getting started","title":"HMatrices._aca_full_pivot","text":"_aca_full_pivot(M)\n\nFind the index of the element x ∈ M maximizing its smallest singular value. This is equivalent to minimizing the spectral norm of the inverse of x.\n\nWhen x is a scalar, this is simply the element with largest absolute value.\n\nSee also: _aca_partial_pivot.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._aca_partial","page":"Getting started","title":"HMatrices._aca_partial","text":"_aca_partial(K,irange,jrange,atol,rmax,rtol,istart=1)\n\nInternal function implementing the adaptive cross-approximation algorithm with partial pivoting. The returned R::RkMatrix provides an approximation to K[irange,jrange] which has either rank is expected to satisfy|M - R| < max(atol,rtol*|M|)`, but this inequality may fail to hold due to the various errors involved in estimating the error and |M|.\n\n\n\n\n\n","category":"function"},{"location":"#HMatrices._aca_partial_pivot-Tuple{Any, Any}","page":"Getting started","title":"HMatrices._aca_partial_pivot","text":"_aca_partial_pivot(v,I)\n\nFind in the valid set I the index of the element x ∈ v maximizing its smallest singular value. This is equivalent to minimizing the spectral norm of the inverse of x.\n\nWhen x is a scalar, this is simply the element with largest absolute value.\n\nThis general implementation should work for both scalar as well as tensor-valued kernels; see (https://www.sciencedirect.com/science/article/pii/S0021999117306721)[https://www.sciencedirect.com/science/article/pii/S0021999117306721] for more details.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._build_block_structure!-Union{Tuple{T}, Tuple{R}, Tuple{Any, HMatrix{R, T}}} where {R, T}","page":"Getting started","title":"HMatrices._build_block_structure!","text":"_build_block_structure!(adm_fun,current_node)\n\nRecursive constructor for HMatrix block structure. Should not be called directly.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._hgemv_recursive!-Tuple{AbstractVector{T} where T, Union{HMatrix, LinearAlgebra.Adjoint{var\"#s58\", var\"#s57\"} where {var\"#s58\", var\"#s57\"<:HMatrix}}, AbstractVector{T} where T, Any}","page":"Getting started","title":"HMatrices._hgemv_recursive!","text":"_hgemv_recursive!(C,A,B,offset)\n\nInternal function used to compute C[I] <-- C[I] + A*B[J] where I = rowrange(A) - offset[1] and J = rowrange(B) - offset[2].\n\nThe offset argument is used on the caller side to signal if the original hierarchical matrix had a pivot other than (1,1).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices._update_frob_norm-Tuple{Any, Any, Any}","page":"Getting started","title":"HMatrices._update_frob_norm","text":"_update_frob_norm(acc,A,B)\n\nGiven the Frobenius norm of Rₖ = A[1:end-1]*adjoint(B[1:end-1]) in acc, compute the Frobenius norm of Rₖ₊₁ = A*adjoint(B) efficiently.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.assemble_cpu!-Tuple{Any, Any, Any}","page":"Getting started","title":"HMatrices.assemble_cpu!","text":"assemble_cpu!(hmat::HMatrix,K,comp)\n\nAssemble data on the leaves of hmat. The admissible leaves are compressed using the compressor comp. This function assumes the structure of hmat has already been intialized, and therefore should not be called directly. See HMatrix information on constructors.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.assemble_threads!-Tuple{Any, Any, Any}","page":"Getting started","title":"HMatrices.assemble_threads!","text":"assemble_threads!(hmat::HMatrix,K,comp)\n\nLike assemble_cpu!, but uses threads to assemble (independent) blocks.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.build_sequence_partition-NTuple{4, Any}","page":"Getting started","title":"HMatrices.build_sequence_partition","text":"build_sequence_partition(seq,nq,cost,nmax)\n\nPartition the sequence seq into nq contiguous subsequences with a maximum of cost of nmax per set. Note that if nmax is too small, this may not be possible (see has_partition).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.compress!-Tuple{HMatrices.RkMatrix, TSVD}","page":"Getting started","title":"HMatrices.compress!","text":"compress!(M::RkMatrix,tsvd::TSVD)\n\nRecompress the matrix R using a truncated svd of R. The implementation uses the qr-svd strategy to efficiently compute svd(R) when rank(R) ≪ min(size(R)).\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.compress!-Tuple{Matrix{T} where T, TSVD}","page":"Getting started","title":"HMatrices.compress!","text":"compress!(M::Matrix,tsvd::TSVD)\n\nRecompress the matrix M using a truncated svd and output an RkMatrix. The data in M is invalidated in the process.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.compression_ratio-Tuple{HMatrices.RkMatrix}","page":"Getting started","title":"HMatrices.compression_ratio","text":"compression_ratio(R::RkMatrix)\n\nThe ratio of the uncompressed size of R to its compressed size in outer product format.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.compression_ratio-Tuple{HMatrix}","page":"Getting started","title":"HMatrices.compression_ratio","text":"compression_ratio(H::HMatrix)\n\nThe ratio of the uncompressed size of H to its compressed size.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.cost_mv-Tuple{HMatrices.RkMatrix}","page":"Getting started","title":"HMatrices.cost_mv","text":"cost_mv(A::Union{Matrix,SubArray,Adjoint})\n\nA proxy for the computational cost of a matrix/vector product.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.find_optimal_cost","page":"Getting started","title":"HMatrices.find_optimal_cost","text":"find_optimal_cost(seq,nq,cost,tol)\n\nFind an approximation to the cost of an optimal partitioning of seq into nq contiguous subsequent. The optimal cost is the smallest number cmax such that has_partition(seq,nq,cost,cmax) returns true.\n\n\n\n\n\n","category":"function"},{"location":"#HMatrices.flush_to_children!-Tuple{HMatrix}","page":"Getting started","title":"HMatrices.flush_to_children!","text":"flush_to_children!(H::HMatrix,compressor)\n\nTransfer the blocks data to its children. At the end, set H.data to nothing.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.getcol!-Tuple{Any, HMatrices.RkMatrix, Int64}","page":"Getting started","title":"HMatrices.getcol!","text":"getcol!(col,M::AbstractMatrix,j)\n\nFill the entries of col with column j of M.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.getcol-Tuple{HMatrices.RkMatrix, Int64}","page":"Getting started","title":"HMatrices.getcol","text":"getcol(M::AbstractMatrix,j)\n\nReturn a vector containing the j-th column of M.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.has_partition","page":"Getting started","title":"HMatrices.has_partition","text":"has_partition(v,np,cost,cmax)\n\nGiven a vector v, determine whether or not a partition into np segments is possible where the cost of each partition does not exceed cmax.\n\n\n\n\n\n","category":"function"},{"location":"#HMatrices.hilbert_cartesian_to_linear-Tuple{Integer, Any, Any}","page":"Getting started","title":"HMatrices.hilbert_cartesian_to_linear","text":"hilbert_cartesian_to_linear(n,x,y)\n\nConvert the cartesian indices x,y into a linear index d using a hilbert curve of order n. The coordinates x,y range from 0 to n-1, and the output d ranges from 0 to n^2-1.\n\nSee https://en.wikipedia.org/wiki/Hilbert_curve.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.hilbert_linear_to_cartesian-Tuple{Integer, Any}","page":"Getting started","title":"HMatrices.hilbert_linear_to_cartesian","text":"hilbert_linear_to_cartesian(n,d)\n\nConvert the linear index 0 ≤ d ≤ n^2-1 into the cartesian coordinates 0 ≤ x < n-1 and 0 ≤ y ≤ n-1 on the Hilbert curve of order n.\n\nSee https://en.wikipedia.org/wiki/Hilbert_curve.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.hilbert_partitioning","page":"Getting started","title":"HMatrices.hilbert_partitioning","text":"hilbert_partitioning(H::HMatrix,np,[cost=cost_mv])\n\nPartiotion the leaves of H into np sequences of approximate equal cost (as determined by the cost function) while also trying to maximize the locality of each partition.\n\n\n\n\n\n","category":"function"},{"location":"#HMatrices.hmul!-Tuple{HMatrix, HMatrix, HMatrix, Any, Any, Any}","page":"Getting started","title":"HMatrices.hmul!","text":"hmul!(C::HMatrix,A::HMatrix,B::HMatrix,a,b,compressor)\n\nSimilar to LinearAlgebra.mul! : compute C <-- A*B*a + B*b, where A,B,C are hierarchical matrices and compressor is a function/functor used in the intermediate stages of the multiplication to avoid growring the rank of admissible blocks after addition is performed.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.isclean-Tuple{HMatrix}","page":"Getting started","title":"HMatrices.isclean","text":"isclean(H::HMatrix)\n\nReturn true if H all leaves of H have data, and if the leaves are the only nodes containing data. This is the normal state of an ℋ-matrix, but during intermediate stages of a computation data may be associated with non-leaf nodes for convenience.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.num_stored_elements-Tuple{HMatrices.RkMatrix}","page":"Getting started","title":"HMatrices.num_stored_elements","text":"num_stored_elements(R::RkMatrix)\n\nThe number of entries stored in the representation. Note that this is not length(R).\n\n\n\n\n\n","category":"method"},{"location":"#LinearAlgebra.axpy!-Tuple{Any, Matrix{T} where T, HMatrices.RkMatrix}","page":"Getting started","title":"LinearAlgebra.axpy!","text":"LinearAlgebra.axpy!(a::Number,X::Union{Matrix,RkMatrix,HMatrix},Y::Union{Matrix,RkMatrix,HMatrix})\n\nPerform Y <-- a*X + Y in-place. Note that depending on the types of X and Y, this may require converting from/to different formats during intermdiate calculations.\n\nIn the case where Y is an RkMatrix, the call axpy!(a,X,Y) should typically be followed by recompression stage to keep the rank of Y under control.\n\nIn the case where Y is an HMatrix, the call axpy!(a,X,Y) sums X to the data in the node Y (and not on the leaves). In case Y has no data, it will simply be assigned X. This means that after the call axpy(a,X,Y), the object Y is in a dirty state (see [isclean][@ref]) and usually a call to flush_to_leaves! or flush_to_children! follows.\n\n\n\n\n\n","category":"method"},{"location":"#HMatrices.@hprofile-Tuple{Any}","page":"Getting started","title":"HMatrices.@hprofile","text":"@hprofile\n\nA macro which\n\nresets the default TimerOutputs.get_defaulttimer to zero\nexecute the code block\nprint the profiling details\n\nThis is useful as a coarse-grained profiling strategy in HMatrices to get a rough idea of where time is spent. Note that this relies on TimerOutputs annotations manually inserted in the code.\n\n\n\n\n\n","category":"macro"}]
}
